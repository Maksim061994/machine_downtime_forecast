{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc34e23-d45e-41a6-b6e1-5cd4ff10615a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "data_path = 'X_train.parquet'\n",
    "target_path = 'y_train.parquet'\n",
    "data_test_path = 'X_test.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c761c38-5d65-4f97-a29e-975932ba9763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torcheval.metrics.functional import multiclass_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d4f74c-fdb0-4405-8b7c-604bdcbf4971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(series):\n",
    "    '''\n",
    "        На входу получает историю для одной фичи, данные нормируются от 0 до 1, пропущенные значение интерполируются\n",
    "    '''\n",
    "    data = pd.Series(series.values)\n",
    "    \n",
    "    inter_data= data.interpolate()\n",
    "\n",
    "    np_data = np.array(inter_data)\n",
    "    values = np_data.reshape((len(np_data), 1))\n",
    "    # train the normalization\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaler = scaler.fit(values)\n",
    "    # normalize the dataset and print the first 5 rows\n",
    "    norm_inter_data = scaler.transform(values)\n",
    "    \n",
    "    return norm_inter_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02e0ba88-c4bb-4a1c-bda0-fe8c410bafc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data saved\n"
     ]
    }
   ],
   "source": [
    "df_data = dd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "data4 = df_data.iloc[:,:16]\n",
    "\n",
    "data4 = data4.compute()\n",
    "print('data saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1085ffe3-19cb-40b1-98ef-2c28e04673c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во таргетов у машины №4:  23\n"
     ]
    }
   ],
   "source": [
    "# Загрузка таргетов для обучения\n",
    "target = pd.read_parquet(target_path)\n",
    "\n",
    "target4 = target.iloc[:,93:116].astype(int)\n",
    "print('Кол-во таргетов у машины №4: ', len(target4.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "749d0641-f883-491d-b786-46b268c1652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "target4 = target4.loc[target4.index < '2021-04-01']\n",
    "target4_M3 = target4[target4 != 1].dropna()\n",
    "target4_M3.replace(2,1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5dc2ce82-ba3f-4a8a-9d07-706209c5e4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data4[\"date\"] = data4.index.date\n",
    "data4_M3 = data4.loc[target4_M3.index]\n",
    "data4_M3['ЭКСГАУСТЕР 4. ВИБРАЦИЯ НА ОПОРЕ 4'] = data4_M3['ЭКСГАУСТЕР 4. ВИБРАЦИЯ НА ОПОРЕ 4'].abs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c98790cc-dc47-4a35-803d-9bd753c75cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data4_M3.shape, target4_M3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a91e07-1ff3-4a90-b175-a5be02386ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_columns = list(data4_M3.columns)\n",
    "index_columns = list(data4_M3.index)\n",
    "\n",
    "df_train = pd.DataFrame(columns=list_columns, index = index_columns)\n",
    "\n",
    "for i in list_columns:\n",
    "    current_data = preprocess_data(data4_M3[i])\n",
    "    df_train[i] = current_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3a886b7-60cc-4982-a61c-b626cf5dd025",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = np.array(df_train)\n",
    "# X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f7ef4a13-df08-44c2-adc2-5c18d880a546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a28a71cf-72c1-4103-8508-af89f4cfaf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def absfft(x):\n",
    "    return np.abs(np.fft.fft(x))\n",
    "\n",
    "feat_fft_array = np.copy(X_data)\n",
    "feat_fft_array = np.apply_along_axis(absfft, 1, feat_fft_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb6d5c89-21ad-443a-a6ca-e45f574e245d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 1.]), array([126014216,  33899632]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target4_M3.replace(2,1, inplace=True)\n",
    "np.unique(target4_M3.values, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3652493-54d0-4d18-a072-3c354514914b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(data, target, train_size, valid_pct=0.1, seed=None):\n",
    "    \"\"\"Converts NumPy arrays into PyTorch datsets.\n",
    "    \n",
    "    Three datasets are created in total:\n",
    "        * training dataset\n",
    "        * validation dataset\n",
    "        * testing (un-labelled) dataset\n",
    "\n",
    "    \"\"\"\n",
    "    raw, fft = data\n",
    "    assert len(raw) == len(fft)\n",
    "    sz = train_size\n",
    "    idx = np.arange(sz)\n",
    "    trn_idx, val_idx = train_test_split(\n",
    "        idx, test_size=valid_pct, random_state=seed)\n",
    "    trn_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][trn_idx]).float(), \n",
    "        torch.tensor(fft[:sz][trn_idx]).float(), \n",
    "        torch.tensor(target[:sz][trn_idx]).long())\n",
    "    val_ds = TensorDataset(\n",
    "        torch.tensor(raw[:sz][val_idx]).float(), \n",
    "        torch.tensor(fft[:sz][val_idx]).float(), \n",
    "        torch.tensor(target[:sz][val_idx]).long())\n",
    "    tst_ds = TensorDataset(\n",
    "        torch.tensor(raw[sz:]).float(), \n",
    "        torch.tensor(fft[sz:]).float(), \n",
    "        torch.tensor(target[sz:]).long())\n",
    "    return trn_ds, val_ds, tst_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72a2d6ec-ae93-406f-adcd-9a05cd4cbdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_loaders(data, bs=128, jobs=0):\n",
    "    \"\"\"Wraps the datasets returned by create_datasets function with data loaders.\"\"\"\n",
    "    \n",
    "    trn_ds, val_ds, tst_ds = data\n",
    "    trn_dl = DataLoader(trn_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    val_dl = DataLoader(val_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    tst_dl = DataLoader(tst_ds, batch_size=bs, shuffle=False, num_workers=jobs)\n",
    "    return trn_dl, val_dl, tst_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fffe28cc-e6d4-4fc8-97c8-cb2bbfdc42fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_sz = int(X_data.shape[0]*0.7)\n",
    "seed = 42\n",
    "data = (X_data, feat_fft_array)\n",
    "\n",
    "# datasets = create_datasets(data, target_new, trn_sz, seed=seed)\n",
    "\n",
    "datasets = create_datasets(data, np.array(target4_M3), trn_sz, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190f56d2-1b01-4126-b7e2-47a5f9342135",
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl, val_dl, tst_dl = create_loaders(datasets, bs=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a99c9854-824f-4678-a802-fcc7b5964096",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_predict(sigmoid_prob, y_true):\n",
    "    \n",
    "    y_pred = torch.as_tensor((sigmoid_prob - 0.5) > 0, dtype=torch.int32)\n",
    "    TP = ((y_pred == 1) * (y_true == 1)).sum()\n",
    "    FP = ((y_pred == 1) * (y_true != 1)).sum()\n",
    "    FN = ((y_pred != 1) * (y_true == 1)).sum()\n",
    "    J = TP/(TP+FP+FN)\n",
    "    J = J/len(y_pred)\n",
    "    \n",
    "    return J.cpu().detach().numpy().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f9be09-b04d-46f8-8d12-2e1bd510fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class _SepConv1d(nn.Module):\n",
    "    \"\"\"A simple separable convolution implementation.\n",
    "    \n",
    "    The separable convlution is a method to reduce number of the parameters \n",
    "    in the deep learning network for slight decrease in predictions quality.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad):\n",
    "        super().__init__()\n",
    "        self.depthwise = nn.Conv1d(ni, ni, kernel, stride, padding=pad, groups=ni)\n",
    "        self.pointwise = nn.Conv1d(ni, no, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.pointwise(self.depthwise(x))\n",
    "    \n",
    "class SepConv1d(nn.Module):\n",
    "    \"\"\"Implementes a 1-d convolution with 'batteries included'.\n",
    "    \n",
    "    The module adds (optionally) activation function and dropout layers right after\n",
    "    a separable convolution layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, ni, no, kernel, stride, pad, drop=None,\n",
    "                 activ=lambda: nn.ReLU(inplace=True)):\n",
    "    \n",
    "        super().__init__()\n",
    "        assert drop is None or (0.0 < drop < 1.0)\n",
    "        layers = [_SepConv1d(ni, no, kernel, stride, pad)]\n",
    "        if activ:\n",
    "            layers.append(activ())\n",
    "        if drop is not None:\n",
    "            layers.append(nn.Dropout(drop))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "        \n",
    "    def forward(self, x): \n",
    "        return self.layers(x)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    \"\"\"Converts N-dimensional tensor into 'flat' one.\"\"\"\n",
    "\n",
    "    def __init__(self, keep_batch_dim=True):\n",
    "        super().__init__()\n",
    "        self.keep_batch_dim = keep_batch_dim\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.keep_batch_dim:\n",
    "            return x.transpose(1, 0)\n",
    "        return x.transpose(1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ad09d068-4740-477e-b2a4-de951c121105",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, raw_ni, fft_ni, no, drop=.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.raw = nn.Sequential(\n",
    "            SepConv1d(    raw_ni,  32, 7, 2, 3, drop=drop),\n",
    "            SepConv1d(    32,  64, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(    64, 128, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 256, 5, 4, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(256, 128), nn.PReLU(), nn.BatchNorm1d(128),\n",
    "            nn.Dropout(drop), nn.Linear(128, 64), nn.PReLU(), nn.BatchNorm1d(64))\n",
    "        \n",
    "        self.fft = nn.Sequential(\n",
    "            SepConv1d(    fft_ni,  32, 7, 2, 3, drop=drop),\n",
    "            SepConv1d(    32,  64, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(    64, 128, 5, 4, 2, drop=drop),\n",
    "            SepConv1d(   128, 256, 5, 4, 2),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(drop), nn.Linear(256, 128), nn.PReLU(), nn.BatchNorm1d(128),\n",
    "            nn.Dropout(drop), nn.Linear(128, 64), nn.PReLU(), nn.BatchNorm1d(64))\n",
    "        \n",
    "\n",
    "        self.out1 = nn.Sequential(\n",
    "            nn.Linear(128, 512), nn.ReLU(inplace=True), nn.Linear(512, 128), nn.ReLU(inplace=True), nn.Linear(128, no))\n",
    "\n",
    "    def forward(self, t_raw, t_fft):\n",
    "        raw_out = self.raw(t_raw)\n",
    "        fft_out = self.fft(t_fft)\n",
    "        t_in = torch.cat([raw_out, fft_out], dim=1)        \n",
    "        out1 = self.out1(t_in)\n",
    "        return out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9d3ebe3b-5922-443d-99b4-848fd7ba9894",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start model training\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:2'\n",
    "\n",
    "lr = 0.001\n",
    "n_epochs = 10\n",
    "num_classes = 23\n",
    "best_acc = 0\n",
    "loss_history = []\n",
    "acc_history = []\n",
    "\n",
    "raw_feat = X_data.shape[1]\n",
    "fft_feat = feat_fft_array.shape[1]\n",
    "\n",
    "model = Classifier(raw_feat, fft_feat, num_classes).to(device)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "opt = optim.Adam(model.parameters(), lr=lr, weight_decay=0.01)\n",
    "\n",
    "print('Start model training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b3c752c-17e4-42d5-b15a-3af0385b5bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61748305527440819276f3a2ab6dfe15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e34dcb5833e4dab88a79293ddfcaf15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 1 Train_loss 0.2454\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35947add80fe458b8dae75ff432f15f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 2 Train_loss 0.2460\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a6ee92130af45cc978a07e2fc7536ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 3 Train_loss 0.2424\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d3ef1d678d45878b2f208460d4de56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 4 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0445e00ed105402aa8285ecbff2c38f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 5 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7e08688e8a4806b639b0eb5fdaf5a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 6 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b697049fb3c545b09f80964bc16ba2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 7 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a17e04fd06ed4364977fa4be631c1b0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 8 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3880da6fb374be5967e88f44520b5d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 9 Train_loss 0.2419\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ee8eb1905648e4bf20c87287065687",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1070 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Номер эпохи 10 Train_loss 0.2419\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(1, n_epochs + 1)):\n",
    "    \n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(trn_dl):\n",
    "        x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "        opt.zero_grad()\n",
    "        X_raw = x_raw[:,:,None]\n",
    "        X_fft = x_fft[:,:,None]\n",
    "        out = model(X_raw, X_fft)\n",
    "        loss = criterion(out, y_batch.float())\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    \n",
    "    \n",
    "    epoch_loss /= len(trn_dl)\n",
    "    if epoch % 1 == 0:\n",
    "        print( 'Номер эпохи', epoch, 'Train_loss', \"%.4f\" % epoch_loss)\n",
    "    loss_history.append(epoch_loss)\n",
    "    \n",
    "#     if epoch % 1 == 0:\n",
    "#         model.eval()\n",
    "#         correct, total = 0, 0\n",
    "#         acc = 0\n",
    "#         for batch in tqdm(val_dl):\n",
    "#             x_raw, x_fft, y_batch = [t.to(device) for t in batch]\n",
    "            \n",
    "#             X_raw = x_raw[:,:,None]\n",
    "#             X_fft = x_fft[:,:,None]\n",
    "#             out1, out2 = model(X_raw, X_fft)\n",
    "\n",
    "#             out = torch.concatenate([out1[:,:, None],out2[:,:, None]], axis = 2)\n",
    "\n",
    "#             softmax_prob = torch.sigmoid(out)\n",
    "#             accuracy = calculate_predict(softmax_prob)\n",
    "#             acc += accuracy\n",
    "#             total += y_batch.size(0)\n",
    "\n",
    "#         acc = acc / total\n",
    "#         print( 'Номер эпохи', epoch, 'Accuracy_val', \"%.6f\" % acc)\n",
    "#         acc_history.append(acc)\n",
    "            \n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "56b7e3b5-76ed-4e71-88d3-a1330dc90e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Ex4_M3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb3d6ff0-ec8c-4645-a402-b7e238e56571",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
