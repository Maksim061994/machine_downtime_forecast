{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80eec41a-46f5-408c-a578-2b691751eebe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.9/site-packages (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.9/site-packages (from openpyxl) (1.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f877478-b5ae-40e4-a2b0-207b6d25d6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "import dask.dataframe as dd\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "data_test_path = '/home/jovyan/work/СеверСтальХакатон/X_test.parquet'\n",
    "label_path = '/home/jovyan/work/СеверСтальХакатон/y_train.parquet'\n",
    "PATH_TO_TEST_INTERVALS = 'test_intervals.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1ee439f-0599-43a7-b3c8-dcd0a823490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(data_path):\n",
    "    \n",
    "    df_data = dd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "    df_data = df_data.compute()\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "664c8bcd-b2a0-41e5-ac1d-d8194b4616e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df_data):\n",
    "    \n",
    "    df_data.interpolate(inplace=True)\n",
    "    # нормирование\n",
    "    scaler = MinMaxScaler()\n",
    "    df_preprocess = pd.DataFrame(scaler.fit_transform(df_data.values), columns=df_data.columns, index=df_data.index)\n",
    "\n",
    "    # формирование фичей\n",
    "    feature_window = 240\n",
    "    cols = df_preprocess.columns\n",
    "\n",
    "    for col in tqdm(cols):\n",
    "        df_preprocess[f'{col}_mean'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).mean()\n",
    "        df_preprocess[f'{col}_median'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).median()\n",
    "        df_preprocess[f'{col}_max'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).max()\n",
    "        df_preprocess[f'{col}_min'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).min()\n",
    "        df_preprocess[f'{col}_std'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).std()\n",
    "        df_preprocess[f'{col}_quantile25'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.25)\n",
    "        df_preprocess[f'{col}_quantile75'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.75)\n",
    "        df_preprocess[f'{col}_quantile95'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.95)\n",
    "        df_preprocess[f'{col}_range'] = df_preprocess[f'{col}_max'] - df_preprocess[f'{col}_min']\n",
    "        df_preprocess[f'{col}_Max/Min'] = df_preprocess[f'{col}_max'] / df_preprocess[f'{col}_min']\n",
    "    \n",
    "    # Чистим данные, заменяем nan и inf на ffill\n",
    "    df_preprocess.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_preprocess.ffill(inplace=True)\n",
    "    df_preprocess.dropna(inplace=True)\n",
    "    \n",
    "    return df_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbc174ca-fcf3-4d31-b718-e338495e3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(X_pred, model_name = 'random_forest.joblib'):\n",
    "    \n",
    "    X_pred = X_pred.values\n",
    "    loaded_model = joblib.load(model_name)\n",
    "    y_pred = loaded_model.predict(X_pred)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46f98fdb-4727-4b42-992f-86d18e6bba04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_exgauster_columns_dicts(X_train, y_train):\n",
    "    \n",
    "    all_columns = list(X_train.columns)\n",
    "    x_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'ЭКСГАУСТЕР {exg_number}'\n",
    "        x_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    all_columns = list(y_train.columns)\n",
    "    y_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'№{exg_number}'\n",
    "        y_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    return x_columns_dict, y_columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fc784d1-6cdc-4a6f-a154-403834235084",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = read_parquet(data_test_path)\n",
    "y_data = read_parquet(label_path)\n",
    "\n",
    "x_columns_dict, y_columns_dict = get_single_exgauster_columns_dicts(data, y_data)\n",
    "\n",
    "table = pd.read_excel(PATH_TO_TEST_INTERVALS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d7e75c0-43b6-47a2-a435-40dfdaa0e61f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe6c9c77aec4c11a6dc2b68d305d35d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c16693478f52428699929e8a9b77de28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   52.3s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  6.0min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91566f96a1a5444e91af05b3a03f3f07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  8.1min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b73c9195dd4235b25d79409b61da54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   49.9s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  5.9min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aca24882586b4f7b8f30f34bce14c383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   58.4s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  6.6min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7035c8bf39134f059d9213df5b8abccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  7.8min finished\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a7a101151b94c7b9ae740f2046689f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:  6.5min finished\n"
     ]
    }
   ],
   "source": [
    "ex_number = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "\n",
    "for i in tqdm(ex_number):\n",
    "    \n",
    "    X_data = data[x_columns_dict[i]]\n",
    "    columns_names = y_columns_dict[i]\n",
    "    X_data = make_features(X_data)\n",
    "    \n",
    "    df_columns = pd.DataFrame(index = X_data.index ,columns = columns_names)\n",
    "    \n",
    "    pred = predict_model(X_data, model_name = f'exg_{i}.joblib')\n",
    "    \n",
    "    df_columns[columns_names] = pred\n",
    "    df_columns.replace(1, 2, inplace=True)\n",
    "    \n",
    "    file_name = f'submit{i}_M3.pkl'\n",
    "    df_columns[columns_names].to_pickle(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3138aa-b317-4fc2-83d2-a596815cc2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
