{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "514d2afd-6ac4-42eb-84f1-ec3cd9b4b0b2",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.26.149-py3-none-any.whl (135 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.6/135.6 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.7.0,>=0.6.0\n",
      "  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.8/79.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.30.0,>=1.29.149\n",
      "  Downloading botocore-1.29.149-py3-none-any.whl (10.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.25.4 in /opt/conda/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.149->boto3) (1.26.11)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/lib/python3.9/site-packages (from botocore<1.30.0,>=1.29.149->boto3) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.30.0,>=1.29.149->boto3) (1.16.0)\n",
      "Installing collected packages: jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.26.149 botocore-1.29.149 jmespath-1.0.1 s3transfer-0.6.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.1.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install mlflow==2.1.1\n",
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "da8b66b7-2d56-408d-95cb-0288a5782387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('postgresql+psycopg2://postgres:JD643JcviPvhnRtbf@tis5000.vniizht.lan:5433/hakaton',\n",
       " 's3://mlflow/3/7e42448501e041ca99d77f73cb6d5d29/artifacts')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "data_train_path = '/home/jovyan/work/СеверСтальХакатон/X_train.parquet'\n",
    "label_train_path = '/home/jovyan/work/СеверСтальХакатон/y_train.parquet'\n",
    "\n",
    "ex_number = [4, 5, 6, 7, 8, 9]\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'postgresql+psycopg2://postgres:JD643JcviPvhnRtbf@tis5000.vniizht.lan:5433/hakaton'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://tis5000.vniizht.lan:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'hakaton'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'JD643JcviPvhnRtbf'\n",
    "mlflow.set_experiment(\"exg-machine-m3-forecast\")\n",
    "\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "mlflow.get_registry_uri(), mlflow.get_artifact_uri()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4ce00f3-e506-4d8d-9b72-455073bb9cac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_parquet(data_path):\n",
    "    \n",
    "    df_data = dd.read_parquet(data_path, engine=\"pyarrow\")\n",
    "    df_data = df_data.compute()\n",
    "    \n",
    "    return df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e4b34ef-971e-41ed-a711-5046705ce6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_label_M3(y_data):\n",
    "    \n",
    "    y_data = y_data[y_data != 1].dropna()\n",
    "    y_data.replace(2,1, inplace=True)\n",
    "    \n",
    "    return y_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23bb82d1-7491-4469-94af-cb7f5e970ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_exgauster_columns_dicts(X_train, y_train):\n",
    "    \n",
    "    all_columns = list(X_train.columns)\n",
    "    x_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'ЭКСГАУСТЕР {exg_number}'\n",
    "        x_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    all_columns = list(y_train.columns)\n",
    "    y_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'№{exg_number}'\n",
    "        y_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    return x_columns_dict, y_columns_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78b62e11-bcb9-4811-9011-32d7ebe1bd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_features(df_data):\n",
    "    \n",
    "    df_data.interpolate(inplace=True)\n",
    "    # нормирование\n",
    "    scaler = MinMaxScaler()\n",
    "    df_preprocess = pd.DataFrame(scaler.fit_transform(df_data.values), columns=df_data.columns, index=df_data.index)\n",
    "\n",
    "    # формирование фичей\n",
    "    feature_window = 240\n",
    "    cols = df_preprocess.columns\n",
    "\n",
    "    for col in tqdm(cols):\n",
    "        df_preprocess[f'{col}_mean'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).mean()\n",
    "        df_preprocess[f'{col}_median'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).median()\n",
    "        df_preprocess[f'{col}_max'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).max()\n",
    "        df_preprocess[f'{col}_min'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).min()\n",
    "        df_preprocess[f'{col}_std'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).std()\n",
    "        df_preprocess[f'{col}_quantile25'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.25)\n",
    "        df_preprocess[f'{col}_quantile75'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.75)\n",
    "        df_preprocess[f'{col}_quantile95'] = df_preprocess[col].rolling(min_periods=1, window=feature_window).quantile(0.95)\n",
    "        df_preprocess[f'{col}_range'] = df_preprocess[f'{col}_max'] - df_preprocess[f'{col}_min']\n",
    "        df_preprocess[f'{col}_Max/Min'] = df_preprocess[f'{col}_max'] / df_preprocess[f'{col}_min']\n",
    "    \n",
    "    # Чистим данные, заменяем nan и inf на ffill\n",
    "    df_preprocess.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    df_preprocess.ffill(inplace=True)\n",
    "    df_preprocess.dropna(inplace=True)\n",
    "    \n",
    "    return df_preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab2bb167-d55e-46d7-af69-38dc05451218",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X_data, y_data):\n",
    "    \n",
    "    assert X_data.shape[0] == y_data.shape[0] , 'Разное кол-во примеров у фичей и таргетов'\n",
    "    \n",
    "    X_test_2019 = X_data.loc[(X_data.index.year == 2019)&(X_data.index.month == 8)&(X_data.index.day < 16)]\n",
    "    X_test_2020 = X_data.loc[(X_data.index.year == 2020)&(X_data.index.month == 8)&(X_data.index.day > 16)]\n",
    "    X_test_2021 = X_data.loc[(X_data.index.year == 2021)&(X_data.index.month == 4)&(X_data.index.day < 16)]\n",
    "    \n",
    "    y_test_2019 = y_data.loc[X_test_2019.index].values\n",
    "    y_test_2020 = y_data.loc[X_test_2020.index].values\n",
    "    y_test_2021 = y_data.loc[X_test_2021.index].values\n",
    "    \n",
    "    idx1 = X_test_2019.index\n",
    "    idx2 = X_test_2020.index\n",
    "    idx3 = X_test_2021.index\n",
    "    \n",
    "    drop_index = idx1.append([idx2, idx3])\n",
    "    \n",
    "    X_train = X_data.drop(drop_index)\n",
    "    y_train = y_data.drop(drop_index)\n",
    "    \n",
    "    X_test = pd.concat([X_test_2019,X_test_2020, X_test_2021])\n",
    "    y_test = y_data.loc[X_test.index]\n",
    "    \n",
    "    return X_train.values, y_train.values, X_test.values, y_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a3fa61f-c2f4-41a3-9d30-02840dfa0836",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(data, number_exg):\n",
    "    if number_exg == 4:\n",
    "        data = data[(data['ЭКСГАУСТЕР 4. ВИБРАЦИЯ НА ОПОРЕ 4'] < 15)&(data['ЭКСГАУСТЕР 4. ВИБРАЦИЯ НА ОПОРЕ 4'] > -20)]\n",
    "    elif number_exg == 7:\n",
    "        data = data[(data['ЭКСГАУСТЕР 7. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 2'] < 150)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 7. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 3'] < 150)&(data['ЭКСГАУСТЕР 7. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 3'] > -50)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 7. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 4'] < 150)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 7. ТЕМПЕРАТУРА МАСЛА В МАСЛОБЛОКЕ'] < 150)]\n",
    "    elif number_exg == 8:\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ТОК РОТОРА 1'] > 0)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ТОК РОТОРА 2'] > 0)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 2'] < 100)&(data['ЭКСГАУСТЕР 8. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 2'] > -50)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 4'] < 100)&(data['ЭКСГАУСТЕР 8. ТЕМПЕРАТУРА ПОДШИПНИКА НА ОПОРЕ 4'] > -50)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ТЕМПЕРАТУРА МАСЛА В СИСТЕМЕ'] > -20)]\n",
    "        data = data[(data['ЭКСГАУСТЕР 8. ВИБРАЦИЯ НА ОПОРЕ 4. ПРОДОЛЬНАЯ.'] > -40)]\n",
    "    return data\n",
    "\n",
    "def calculate_predict(y_pred, y_true): \n",
    "    \n",
    "    TP = ((y_pred == 1) * (y_true == 1)).sum()\n",
    "    FP = ((y_pred == 1) * (y_true != 1)).sum()\n",
    "    FN = ((y_pred != 1) * (y_true == 1)).sum()\n",
    "    \n",
    "    J = TP/(TP+FP+FN)\n",
    "    \n",
    "    return J\n",
    "\n",
    "def fit_model(\n",
    "    X_train, y_train, \n",
    "    X_test, y_test, \n",
    "    save_name = 'random_forest.joblib',\n",
    "    n_estimators=100, max_depth=10, min_samples_split=5\n",
    "):    \n",
    "    \n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, verbose=1, n_jobs=20)\n",
    "    model.fit(X_train, y_train)\n",
    "        \n",
    "    y_pred = model.predict(X_test)\n",
    "    \n",
    "    f1_score = metrics.f1_score(y_test, y_pred, average='weighted')\n",
    "    custome_score = calculate_predict(y_pred, y_test)\n",
    "    \n",
    "    print(\"F1: \", f1_score)\n",
    "    print(\"Custom metric: \", custome_score)\n",
    "        \n",
    "    joblib.dump(model, save_name)\n",
    "    \n",
    "    return model, f1_score, custome_score, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c414d5c-8237-40f4-ad16-84247baa7043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e11bb2deb23243faa8cbe75281cf12f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d767ef412fc74717b359bd0011f98a0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  5.0min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 24.7min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    6.7s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:   48.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9260801478410117\n",
      "Custom metric:  0.8799229044523751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/08 15:44:19 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/6cd0d5df29254a46943e6baf0612e118/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e87e5ec157ed48ecadcd026873d44b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  4.2min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 21.0min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:   34.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9125005354131136\n",
      "Custom metric:  0.8227462935547165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/08 16:15:29 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/f6ecee48cfcc4c3a8bcf96f022002e7a/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d02679f85e2b4c2ab0868992b3e7b7e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  2.6min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 12.8min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    3.7s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:   24.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9582547057088369\n",
      "Custom metric:  0.947124856935306\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/08 16:34:21 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/6cf3b56de980497d8a647bd01f2acbc1/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "277b91da4ffc4e609f2c84f3fae72ae0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  2.8min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 13.7min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:   32.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9056769256933375\n",
      "Custom metric:  0.8299789869035006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/08 16:54:33 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/6f0763345cde46519ffe946420ab0cbc/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7388458909844fba4a650adc57fdd7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:  4.4min\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed: 22.0min finished\n",
      "[Parallel(n_jobs=20)]: Using backend ThreadingBackend with 20 concurrent workers.\n",
      "[Parallel(n_jobs=20)]: Done  10 tasks      | elapsed:    5.3s\n",
      "[Parallel(n_jobs=20)]: Done 100 out of 100 | elapsed:   38.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:  0.9528122902897285\n",
      "Custom metric:  0.8908199017612884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/08 17:26:54 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/4a3664f632a743c5b7ffe5a5c38c737b/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "X_train_data = read_parquet(data_train_path)\n",
    "y_train_data = read_parquet(label_train_path)\n",
    "\n",
    "x_columns_dict, y_columns_dict = get_single_exgauster_columns_dicts(X_train_data, y_train_data)\n",
    "\n",
    "for i in tqdm(ex_number):    \n",
    "    run_name = f\"exg_{i}_rf\"\n",
    "    \n",
    "    X_data = X_train_data[x_columns_dict[i]]\n",
    "    X_data = preprocessing_data(X_data, i)\n",
    "\n",
    "    y_data = y_train_data[y_columns_dict[i]]\n",
    "    y_data = y_data.loc[X_data.index]\n",
    "    assert y_data.shape[0] == X_data.shape[0]\n",
    "    \n",
    "    y_data = preprocess_label_M3(y_data)\n",
    "    \n",
    "    X_data = make_features(X_data.loc[y_data.index])\n",
    "    y_data = y_data.loc[X_data.index]\n",
    "\n",
    "    X_train, y_train, X_test, y_test = train_test_split(X_data, y_data)\n",
    "    \n",
    "    with mlflow.start_run(run_name=run_name):\n",
    "        \n",
    "        n_estimators=100\n",
    "        max_depth=10\n",
    "        min_samples_split=5\n",
    "        \n",
    "        # train model\n",
    "        model, f1_score, target_metric, y_pred = fit_model(\n",
    "            X_train, y_train, X_test, y_test, save_name = f'exg_{i}.joblib',\n",
    "            n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split\n",
    "        )\n",
    "\n",
    "        # log result train\n",
    "        mlflow.log_param(\"n_estimators\", n_estimators)\n",
    "        mlflow.log_param(\"max_depth\", max_depth)\n",
    "        mlflow.log_param(\"min_samples_split\", min_samples_split)\n",
    "        mlflow.log_metric(\"f1_score\", f1_score)\n",
    "        mlflow.log_metric(\"target_metric\", target_metric)\n",
    "        \n",
    "        # save model\n",
    "        sign_data = pd.DataFrame(X_test, columns=X_data.columns)\n",
    "        signature = infer_signature(sign_data, y_pred)\n",
    "        mlflow.sklearn.log_model(model, \"model\", signature=signature)\n",
    "        \n",
    "    mlflow.end_run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
