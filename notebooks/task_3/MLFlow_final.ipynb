{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "263e7a10-8222-4b52-aa62-8333c9ac4b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow==2.1.1\n",
    "# !pip install openpyxl\n",
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91738818-4c8c-48f1-bf56-35caf4bf5bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.onnx\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'postgresql+psycopg2://postgres:JD643JcviPvhnRtbf@tis5000.vniizht.lan:5433/hakaton'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://tis5000.vniizht.lan:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'hakaton'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'JD643JcviPvhnRtbf'\n",
    "mlflow.set_experiment(\"exg-machine-downtime-forecast\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f21f692a-0160-4200-a716-3867e0bfebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_TO_X_TRAIN = 'data/datasets/X_train.parquet'\n",
    "PATH_TO_Y_TRAIN = 'data/datasets/y_train.parquet'\n",
    "PATH_TO_MESSAGES = 'data/datasets/messages.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38833712-73a5-4253-b897-48ba821f2525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce812b41-67b1-42aa-915b-826ec337b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd\n",
    "\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "31d2bf4a-49a3-458e-bd50-c80c5003bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_exgauster_columns_dicts(X_train, y_train):\n",
    "    \n",
    "    all_columns = list(X_train.columns)\n",
    "    x_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'ЭКСГАУСТЕР {exg_number}'\n",
    "        x_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    all_columns = list(y_train.columns)\n",
    "    y_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'№{exg_number}'\n",
    "        y_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    return x_columns_dict, y_columns_dict\n",
    "\n",
    "x_columns_dict, y_columns_dict = get_single_exgauster_columns_dicts(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "01b7ce89-f0ef-48cd-9c7e-e8a9cd5c5911",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "def add_features(X_train_full, x_columns_dict, exg_number):\n",
    "    \n",
    "    features = X_train_full[x_columns_dict[exg_number]].compute()\n",
    "    features[\"date\"] = features.index.date\n",
    "    \n",
    "    features[f'ЭКСГАУСТЕР {exg_number}. ВИБРАЦИЯ НА ОПОРЕ 4'] = features[f'ЭКСГАУСТЕР {exg_number}. ВИБРАЦИЯ НА ОПОРЕ 4'].abs()\n",
    "    \n",
    "    def compute_window_features(data, name_f):\n",
    "        windows = ['7D', '30D']\n",
    "        for f in tqdm(name_f):\n",
    "            for window in windows:\n",
    "                data[f\"{f}_{window}_mean\"] = data[f].rolling(window, min_periods=1).mean()\n",
    "                data[f\"{f}_{window}_std\"] = data[f].rolling(window, min_periods=1).std()\n",
    "                data[f\"{f}_{window}_median\"] = data[f].rolling(window, min_periods=1).median()\n",
    "                data[f\"{f}_{window}_max\"] = data[f].rolling(window, min_periods=1).max()\n",
    "            # data[f\"{f}_1D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_1D_mean\"]\n",
    "            data[f\"{f}_7D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_7D_mean\"]\n",
    "            data[f\"{f}_30D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_30D_mean\"]\n",
    "            # data[f\"{f}_1D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_1D_median\"]\n",
    "            data[f\"{f}_7D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_7D_median\"]\n",
    "            data[f\"{f}_30D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_30D_median\"]        \n",
    "            data[f\"{f}_diff_between_values\"] = data[f\"{f}\"] / data[f\"{f}\"].rolling(1, min_periods=1).mean()\n",
    "        return data\n",
    "    \n",
    "    x_data_train = compute_window_features(features, x_columns_dict[exg_number])    \n",
    "    return x_data_train\n",
    "\n",
    "\n",
    "def add_target(y_train_full, y_columns_dict, exg_number, tm):\n",
    "    \n",
    "    messages = pd.read_excel(PATH_TO_MESSAGES)\n",
    "    messages[\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"] = pd.to_datetime(messages[\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"])\n",
    "    messages[\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"] = pd.to_datetime(messages[\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"])\n",
    "\n",
    "    fail_dates = messages[\n",
    "        (messages[\"ВИД_СООБЩЕНИЯ\"] == \"M1\")&\n",
    "        (messages[\"ИМЯ_МАШИНЫ\"] == f\"ЭКСГАУСТЕР А/М №{exg_number}\")&\n",
    "        (True if not tm else messages[\"НАЗВАНИЕ_ТЕХ_МЕСТА\"] == f\"{tm}\")&\n",
    "        ((messages[\"ОПИСАНИЕ\"] != \"ТО\")|\n",
    "        (messages[\"ОПИСАНИЕ\"] != \"ТО(замена редуктора газовой задвижки №4)\")|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО согласованное')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'Согласованное ТО')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО(согласованное)')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО (замена щеток на эл/двиг. эксг-ра)'))\n",
    "    ]\n",
    "    \n",
    "    if tm:\n",
    "        labels = y_train_full[f'Y_ЭКСГАУСТЕР А/М №{exg_number}_{tm}'].compute()\n",
    "    else:\n",
    "        labels = y_train_full[y_columns_dict[exg_number]].compute()\n",
    "        labels = ((labels==1).sum(axis=1) > 0).astype(int)\n",
    "    \n",
    "    \n",
    "    idx = 0\n",
    "    template = pd.Series(np.zeros(labels.shape[0]))\n",
    "    template.index = labels.index\n",
    "    for i in range(fail_dates.shape[0]):\n",
    "        dt_start = fail_dates.iloc[i][\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"]\n",
    "        dt_end = fail_dates.iloc[i][\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"]\n",
    "\n",
    "        diff = dt_start - labels.iloc[idx:].index\n",
    "        res = (diff).days*24*3600 + diff.seconds\n",
    "        res = pd.Series(res)\n",
    "        res = res[res > 0]\n",
    "        template.iloc[idx:idx+res.shape[0]] = res.values\n",
    "        idx += res.shape[0]\n",
    "        first_zero = labels.index[idx]\n",
    "        shape_fail = labels[(labels.index >= first_zero)&(labels.index <=  dt_end)].shape[0]\n",
    "        idx += shape_fail\n",
    "        \n",
    "    template[idx:] = None\n",
    "    template = template.dropna()\n",
    "    template = template[template != 0]\n",
    "    \n",
    "    template = pd.DataFrame(template, columns=[\"y\"])\n",
    "    return template\n",
    "\n",
    "\n",
    "def get_train_test_data(X_train_full, y_train_full, x_columns_dict, y_columns_dict, exg_number, tm):\n",
    "    \n",
    "    print('adding features')\n",
    "    data = add_features(X_train_full, x_columns_dict, exg_number)\n",
    "    \n",
    "    print('adding targets')\n",
    "    template = add_target(y_train_full, y_columns_dict, exg_number, tm)\n",
    "    \n",
    "    data = data.merge(template, left_index=True, right_index=True)\n",
    "    \n",
    "    print('train test split')\n",
    "    X_train = data.loc[data.index < pd.to_datetime(\"2021-01-01\")]\n",
    "    X_test = data.loc[data.index >= pd.to_datetime(\"2021-01-01\")]\n",
    "\n",
    "    \n",
    "    print('x y split')\n",
    "    y_train = X_train[\"y\"]\n",
    "    X_train.drop(columns=[\"y\",\"date\"], inplace=True)\n",
    "    \n",
    "    y_test = X_test[\"y\"]\n",
    "\n",
    "    X_test.drop(columns=[\"y\",\"date\"], inplace=True)\n",
    "    \n",
    "    print('delete unused data')\n",
    "    del data\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98c2fcff-9d48-4dc0-b8b1-f5ea5a166d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred, alpha):\n",
    "    \n",
    "    weight_sum = 0.0\n",
    "    error = 0.0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        weight_sum += 1\n",
    "        error += (y_pred[i] - y_true[i]) ** 2 * (1 / (y_true[i] * alpha))\n",
    "    \n",
    "    return np.sqrt(error / weight_sum)\n",
    "\n",
    "\n",
    "class OrgRmseObjective(object):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "\n",
    "        result = []\n",
    "        der1 = (targets - approxes) * (1 / (targets * self.alpha))\n",
    "        der2 = -1 * (1 / (targets * self.alpha))\n",
    "\n",
    "        result = [(d1, d2) for (d1, d2) in zip(der1, der2)]\n",
    "        return result\n",
    "\n",
    "\n",
    "class OrgRmseMetric(object):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def get_final_error(self, error, weight):\n",
    "        return np.sqrt(error / (weight + 1e-38))\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = len(approx)\n",
    "\n",
    "        error_sum = (((approx - target) ** 2) * (1 / (target * self.alpha))).sum()\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9eefa5f-d27e-43e2-ac0d-a2f7efe0c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(X_train_full, y_train_full, exg_number, tm: str = None):\n",
    "\n",
    "    depth = 5\n",
    "    iterations = 3000\n",
    "    learning_rate = 0.005\n",
    "    od_type = \"Iter\"\n",
    "    od_wait = 100\n",
    "    lambd = 0.7\n",
    "    model_name = 'catboost'\n",
    "    artifact_path = \"model\"\n",
    "    alpha = 10\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_data(X_train_full, y_train_full, x_columns_dict, y_columns_dict, exg_number, tm)\n",
    "    \n",
    "    print(y_train.shape)\n",
    "    print(y_test.shape)\n",
    "    \n",
    "    print('boxcox')\n",
    "    y_train_boxcox = boxcox1p(y_train, lambd)\n",
    "    y_test_boxcox = boxcox1p(y_test, lambd)\n",
    "\n",
    "    # ПОДШИПНИК ОПОРНЫЙ №2 ЭКСГ. №4\n",
    "    print('Starting train')\n",
    "    \n",
    "    run_name = f'exg_{exg_number}_boxcox' if not tm else f'exg_{exg_number}_{tm}_boxcox'\n",
    "    with mlflow.start_run(run_name=run_name) as run:\n",
    "        run_id = run.info.run_id\n",
    "        experiment_id = run.info.experiment_id\n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\", run_id)\n",
    "        print(\"  experiment_id:\", experiment_id)\n",
    "\n",
    "        # MLflow params\n",
    "        print(\"Parameters:\")\n",
    "        print(\"  depth:\", depth)\n",
    "        print(\"  learning_rate:\", learning_rate)\n",
    "        print(\"  iterations:\", iterations)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"od_type\", od_type)\n",
    "        mlflow.log_param(\"od_wait\", od_wait)\n",
    "        mlflow.log_param(\"lambd_boxcox\", lambd)\n",
    "        mlflow.log_param(\"loss_alpha\", alpha)\n",
    "\n",
    "        # Create and fit model\n",
    "        model = cb.CatBoostRegressor(\n",
    "            depth=depth, iterations=iterations, learning_rate=learning_rate, loss_function=OrgRmseObjective(alpha=alpha),\n",
    "            task_type='CPU', random_seed=13, verbose=50, eval_metric=OrgRmseMetric(alpha=alpha),\n",
    "            od_type=od_type, od_wait=od_wait\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train_boxcox,\n",
    "                        eval_set=(X_test, y_test_boxcox))\n",
    "        if tm:\n",
    "            model_save_name = f\"models/cb_regressor_exg_{exg_number}_{tm}_boxcox_org_loss.cbm\"\n",
    "            preds_df_name = f'test_preds/y_preds_exg_{exg_number}_{tm}.csv'\n",
    "            y_df_save_name = f'test_preds/y_preds_exg_{exg_number}_{tm}.csv'\n",
    "        else:\n",
    "            model_save_name = f\"models/cb_regressor_exg_{exg_number}_boxcox_org_loss.cbm\"\n",
    "            preds_df_name = f'test_preds/y_preds_exg_{exg_number}.csv'\n",
    "            y_df_save_name = f'test_preds/y_preds_exg_{exg_number}.csv'\n",
    "        \n",
    "        model.save_model(model_save_name)\n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        signature = infer_signature(X_test, predictions)\n",
    "        metrics = {\n",
    "           \"mse\": mean_absolute_error(y_test_boxcox, predictions),\n",
    "           \"rmse\": mean_squared_error(y_test_boxcox, predictions, squared=False),\n",
    "           \"mae\": mean_squared_error(y_test_boxcox, predictions),\n",
    "           \"target_metric\": custom_metric(y_test_boxcox, predictions, alpha=alpha),\n",
    "           \"best_iteration\": model.get_best_iteration()\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.catboost.log_model(model, artifact_path, signature=signature)\n",
    "        \n",
    "        # task_1 part\n",
    "        preds_df = pd.DataFrame(predictions)\n",
    "        y_df = pd.DataFrame(y_test_boxcox)\n",
    "\n",
    "        preds_df.to_csv(preds_df_name)\n",
    "        y_df.to_csv(y_df_save_name)\n",
    "                \n",
    "        del X_test\n",
    "        del y_test\n",
    "        del X_train\n",
    "        del y_train\n",
    "        gc.collect()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a531c313-5765-456a-ae97-12af942e7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_all_models():\n",
    "    \n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        print(f'training model for exgauster {exg_number}')\n",
    "        make_model(X_train_full, y_train_full, exg_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c670354d-1d05-4b81-b340-cdd5e2612392",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training model for exgauster 7\n",
      "adding features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd2f29fcaaa4eeca5838f178973f28c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adding targets\n",
      "train test split\n",
      "x y split\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_35443/2729375851.py:101: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train.drop(columns=[\"y\",\"date\"], inplace=True)\n",
      "/tmp/ipykernel_35443/2729375851.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_test.drop(columns=[\"y\",\"date\"], inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete unused data\n",
      "(6181308,)\n",
      "(716505,)\n",
      "boxcox\n",
      "Starting train\n",
      "MLflow:\n",
      "  run_id: ab164797acee437dbcd2057a0968b442\n",
      "  experiment_id: 8\n",
      "Parameters:\n",
      "  depth: 5\n",
      "  learning_rate: 0.005\n",
      "  iterations: 3000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/catboost/core.py:2266: UserWarning: Can't optimze method \"calc_ders_range\" because self argument is used\n",
      "  _check_train_params(params)\n",
      "/opt/conda/lib/python3.9/site-packages/catboost/core.py:2266: UserWarning: Can't optimze method \"evaluate\" because self argument is used\n",
      "  _check_train_params(params)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 145.0354660\ttest: 61.1646135\tbest: 61.1646135 (0)\ttotal: 5.91s\tremaining: 4h 55m 9s\n",
      "50:\tlearn: 141.0099450\ttest: 57.5610102\tbest: 57.5610102 (50)\ttotal: 5m 15s\tremaining: 5h 3m 59s\n",
      "100:\tlearn: 136.5711323\ttest: 55.1973381\tbest: 55.1973381 (100)\ttotal: 10m 34s\tremaining: 5h 3m 20s\n",
      "150:\tlearn: 131.9561558\ttest: 53.4288433\tbest: 53.4288433 (150)\ttotal: 15m 54s\tremaining: 5h\n",
      "200:\tlearn: 127.1408344\ttest: 51.6314015\tbest: 51.6314015 (200)\ttotal: 21m 10s\tremaining: 4h 54m 49s\n",
      "250:\tlearn: 122.6617655\ttest: 50.1049273\tbest: 50.1049273 (250)\ttotal: 26m 26s\tremaining: 4h 49m 35s\n",
      "300:\tlearn: 118.5150367\ttest: 48.8659251\tbest: 48.8659251 (300)\ttotal: 31m 44s\tremaining: 4h 44m 32s\n",
      "350:\tlearn: 114.6863445\ttest: 48.0163277\tbest: 48.0163277 (350)\ttotal: 37m 5s\tremaining: 4h 39m 55s\n",
      "400:\tlearn: 111.0987167\ttest: 47.3841512\tbest: 47.3841512 (400)\ttotal: 42m 26s\tremaining: 4h 35m 6s\n",
      "450:\tlearn: 107.4851934\ttest: 46.9720375\tbest: 46.9720375 (450)\ttotal: 47m 46s\tremaining: 4h 30m 3s\n",
      "500:\tlearn: 104.0875453\ttest: 46.6278480\tbest: 46.6225417 (498)\ttotal: 53m 8s\tremaining: 4h 25m 2s\n",
      "550:\tlearn: 100.7950607\ttest: 46.4401648\tbest: 46.4401648 (550)\ttotal: 58m 28s\tremaining: 4h 19m 51s\n",
      "600:\tlearn: 97.9009602\ttest: 46.3698831\tbest: 46.3635515 (592)\ttotal: 1h 3m 46s\tremaining: 4h 14m 33s\n",
      "650:\tlearn: 94.9977161\ttest: 46.3006809\tbest: 46.2785324 (642)\ttotal: 1h 9m 5s\tremaining: 4h 9m 17s\n",
      "700:\tlearn: 92.2893838\ttest: 46.3423417\tbest: 46.2785324 (642)\ttotal: 1h 14m 24s\tremaining: 4h 4m 1s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 46.27853244\n",
      "bestIteration = 642\n",
      "\n",
      "Shrink model to first 643 iterations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/09 10:39:07 WARNING mlflow.models.model: Logging model metadata to the tracking server has failed, possibly due older server version. The model artifacts have been logged successfully under s3://mlflow/3/ab164797acee437dbcd2057a0968b442/artifacts. In addition to exporting model artifacts, MLflow clients 1.7.0 and above attempt to record model metadata to the tracking store. If logging to a mlflow server via REST, consider upgrading the server version to MLflow 1.7.0 or above. Set logging level to DEBUG via `logging.getLogger(\"mlflow\").setLevel(logging.DEBUG)` to see the full traceback.\n"
     ]
    }
   ],
   "source": [
    "make_all_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17bd302-d0e7-4359-8d4e-981933740ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
