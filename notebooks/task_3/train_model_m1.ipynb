{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91738818-4c8c-48f1-bf56-35caf4bf5bb2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install mlflow\n",
    "# !pip install openpyxl\n",
    "# !pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24bfe3b-90ae-44d6-864e-d7fa70cfd9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.onnx\n",
    "from mlflow.models.signature import infer_signature\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from tqdm.notebook import tqdm\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from scipy.special import boxcox1p, inv_boxcox1p\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "import os\n",
    "import gc\n",
    "\n",
    "\n",
    "os.environ['MLFLOW_TRACKING_URI'] = 'postgresql+psycopg2://postgres:JD643JcviPvhnRtbf@tis5000.vniizht.lan:5433/hakaton'\n",
    "os.environ['MLFLOW_S3_ENDPOINT_URL'] = \"http://tis5000.vniizht.lan:9000\"\n",
    "os.environ['AWS_ACCESS_KEY_ID'] = 'hakaton'\n",
    "os.environ['AWS_SECRET_ACCESS_KEY'] = 'JD643JcviPvhnRtbf'\n",
    "mlflow.set_experiment(\"exg-machine-downtime-forecast\")\n",
    "client = mlflow.tracking.MlflowClient()\n",
    "\n",
    "PATH_TO_X_TRAIN = 'data/X_train.parquet'\n",
    "PATH_TO_Y_TRAIN = 'data/y_train.parquet'\n",
    "PATH_TO_MESSAGES = 'data/messages.xlsx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e041428d-becc-4843-8716-797ca8a24038",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31d2bf4a-49a3-458e-bd50-c80c5003bf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_single_exgauster_columns_dicts(X_train, y_train):\n",
    "    \n",
    "    all_columns = list(X_train.columns)\n",
    "    x_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'ЭКСГАУСТЕР {exg_number}'\n",
    "        x_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    all_columns = list(X_train.columns)\n",
    "    y_columns_dict = {}\n",
    "    for exg_number in [4, 5, 6, 7, 8, 9]:\n",
    "        exg_name = f'№{exg_number}'\n",
    "        y_columns_dict[exg_number] = [col for col in all_columns if exg_name in col]\n",
    "        \n",
    "    return x_columns_dict, y_columns_dict\n",
    "\n",
    "x_columns_dict, y_columns_dict = get_single_exgauster_columns_dicts(X_train_full, y_train_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b7ce89-f0ef-48cd-9c7e-e8a9cd5c5911",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "\n",
    "simplefilter(action=\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "\n",
    "\n",
    "def add_features(X_train_full, x_columns_dict, exg_number):\n",
    "    \n",
    "    features = X_train_full[x_columns_dict[exg_number]].compute()\n",
    "    features[\"date\"] = features.index.date\n",
    "    \n",
    "    # features[f'ЭКСГАУСТЕР {exg_number}. ВИБРАЦИЯ НА ОПОРЕ {exg_number}'] = features[f'ЭКСГАУСТЕР {exg_number}. ВИБРАЦИЯ НА ОПОРЕ 4'].abs()\n",
    "    \n",
    "    def compute_window_features(data, name_f):\n",
    "        windows = ['1h', '1D', '7D', '30D']\n",
    "        for f in tqdm(name_f):\n",
    "            for window in windows:\n",
    "                data[f\"{f}_{window}_mean\"] = data[f].rolling(window, min_periods=1).mean()\n",
    "                data[f\"{f}_{window}_std\"] = data[f].rolling(window, min_periods=1).std()\n",
    "                data[f\"{f}_{window}_median\"] = data[f].rolling(window, min_periods=1).median()\n",
    "                data[f\"{f}_{window}_max\"] = data[f].rolling(window, min_periods=1).max()\n",
    "            data[f\"{f}_1D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_1D_mean\"]\n",
    "            data[f\"{f}_7D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_7D_mean\"]\n",
    "            data[f\"{f}_30D_chg_mean\"] = data[f\"{f}\"]/data[f\"{f}_30D_mean\"]\n",
    "            data[f\"{f}_1D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_1D_median\"]\n",
    "            data[f\"{f}_7D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_7D_median\"]\n",
    "            data[f\"{f}_30D_chg_median\"] = data[f\"{f}\"]/data[f\"{f}_30D_median\"]        \n",
    "            data[f\"{f}_diff_between_values\"] = data[f\"{f}\"] / data[f\"{f}\"].rolling(1, min_periods=1).mean()\n",
    "        return data\n",
    "    \n",
    "    x_data_train = compute_window_features(features, x_columns_dict[exg_number])    \n",
    "    return x_data_train\n",
    "\n",
    "\n",
    "def add_target(y_train_full, y_columns_dict, exg_number):\n",
    "    \n",
    "    messages = pd.read_excel(PATH_TO_MESSAGES)\n",
    "    messages[\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"] = pd.to_datetime(messages[\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"])\n",
    "    messages[\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"] = pd.to_datetime(messages[\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"])\n",
    "\n",
    "    fail_dates = messages[\n",
    "        (messages[\"ВИД_СООБЩЕНИЯ\"] == \"M1\")&\n",
    "        (messages[\"ИМЯ_МАШИНЫ\"] == f\"ЭКСГАУСТЕР А/М №{exg_number}\")&\n",
    "        ((messages[\"ОПИСАНИЕ\"] != \"ТО\")|\n",
    "        (messages[\"ОПИСАНИЕ\"] != \"ТО(замена редуктора газовой задвижки №4)\")|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО согласованное')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'Согласованное ТО')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО(согласованное)')|\n",
    "        (messages[\"ОПИСАНИЕ\"] != 'ТО (замена щеток на эл/двиг. эксг-ра)'))\n",
    "    ]\n",
    "    \n",
    "    labels = y_train_full[y_columns_dict[exg_number]].compute()\n",
    "    labels = ((labels==1).sum(axis=1) > 0).astype(int)\n",
    "    \n",
    "    idx = 0\n",
    "    template = pd.Series(np.zeros(labels.shape[0]))\n",
    "    template.index = labels.index\n",
    "    for i in range(fail_dates.shape[0]):\n",
    "        dt_start = fail_dates.iloc[i][\"ДАТА_НАЧАЛА_НЕИСПРАВНОСТИ\"]\n",
    "        dt_end = fail_dates.iloc[i][\"ДАТА_УСТРАНЕНИЯ_НЕИСПРАВНОСТИ\"]\n",
    "\n",
    "        diff = dt_start - labels.iloc[idx:].index\n",
    "        res = (diff).days*24*3600 + diff.seconds\n",
    "        res = pd.Series(res)\n",
    "        res = res[res > 0]\n",
    "        template.iloc[idx:idx+res.shape[0]] = res.values\n",
    "        idx += res.shape[0]\n",
    "        first_zero = labels.index[idx]\n",
    "        shape_fail = labels[(labels.index >= first_zero)&(labels.index <=  dt_end)].shape[0]\n",
    "        idx += shape_fail\n",
    "    template[idx:] = None\n",
    "    template = template.dropna()\n",
    "    template = template[template != 0]\n",
    "    \n",
    "    template = pd.DataFrame(template, columns=[\"y\"])\n",
    "    return template\n",
    "\n",
    "def get_train_test_data(X_train_full, y_train_full, x_columns_dict, y_columns_dict, exg_number):\n",
    "    \n",
    "    print('adding features')\n",
    "    data = add_features(X_train_full, x_columns_dict, exg_number)\n",
    "    \n",
    "    print('adding targets')\n",
    "    template = add_target(y_train_full, y_columns_dict, exg_number)\n",
    "    data = data.merge(template, left_index=True, right_index=True)\n",
    "    \n",
    "    print('train test split')\n",
    "    X_train = data.loc[(data.index >= pd.to_datetime(\"2020-01-01\"))&(data.index < pd.to_datetime(\"2020-09-01\"))]\n",
    "    X_test = data.loc[(data.index >= pd.to_datetime(\"2020-09-01\"))&(data.index < pd.to_datetime(\"2021-01-01\"))]\n",
    "    \n",
    "    print('x y split')\n",
    "    y_train = X_train[\"y\"]\n",
    "    X_train.drop(columns=[\"y\",\"date\"], inplace=True)\n",
    "    y_test = X_test[\"y\"]\n",
    "    X_test.drop(columns=[\"y\",\"date\"], inplace=True)\n",
    "    \n",
    "    print('delete unused data')\n",
    "    del data\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c2fcff-9d48-4dc0-b8b1-f5ea5a166d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_metric(y_true, y_pred, alpha):\n",
    "    \n",
    "    weight_sum = 0.0\n",
    "    error = 0.0\n",
    "    \n",
    "    for i in range(len(y_pred)):\n",
    "        weight_sum += 1\n",
    "        error += (y_pred[i] - y_true[i]) ** 2 * (1 / (y_true[i] * alpha))\n",
    "    \n",
    "    return np.sqrt(error / weight_sum)\n",
    "\n",
    "\n",
    "class OrgRmseObjective(object):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def calc_ders_range(self, approxes, targets, weights):\n",
    "        assert len(approxes) == len(targets)\n",
    "        if weights is not None:\n",
    "            assert len(weights) == len(approxes)\n",
    "\n",
    "        result = []\n",
    "        for index in range(len(targets)):\n",
    "            der1 = (targets[index] - approxes[index]) * (1 / (targets[index] * self.alpha))\n",
    "            der2 = -1 * (1 / (targets[index] * self.alpha))\n",
    "\n",
    "            if weights is not None:\n",
    "                der1 *= weights[index]\n",
    "                der2 *= weights[index]\n",
    "\n",
    "            result.append((der1, der2))\n",
    "        return result\n",
    "\n",
    "    \n",
    "class OrgRmseMetric(object):\n",
    "    \n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def get_final_error(self, error, weight):\n",
    "        return np.sqrt(error / (weight + 1e-38))\n",
    "\n",
    "    def is_max_optimal(self):\n",
    "        return False\n",
    "\n",
    "    def evaluate(self, approxes, target, weight):\n",
    "        assert len(approxes) == 1\n",
    "        assert len(target) == len(approxes[0])\n",
    "\n",
    "        approx = approxes[0]\n",
    "\n",
    "        error_sum = 0.0\n",
    "        weight_sum = 0.0\n",
    "\n",
    "        for i in range(len(approx)):\n",
    "            w = 1.0 if weight is None else weight[i]\n",
    "            weight_sum += w\n",
    "            error_sum += w * ((approx[i] - target[i]) ** 2) * (1 / (target[i] * self.alpha))\n",
    "\n",
    "        return error_sum, weight_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9eefa5f-d27e-43e2-ac0d-a2f7efe0c163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(\n",
    "    X_train_full, y_train_full, exg_number, \n",
    "    depth=4, iterations=2000, learning_rate=0.001,\n",
    "    od_type=\"Iter\", od_wait=500, lambd=0.7, verbose=100\n",
    "):\n",
    "\n",
    "    model_name = 'catboost'\n",
    "    artifact_path = \"model\"\n",
    "    alpha = 10\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = get_train_test_data(X_train_full, y_train_full, x_columns_dict, y_columns_dict, exg_number)\n",
    "    \n",
    "    print('boxcox')\n",
    "    y_train_boxcox = boxcox1p(y_train, lambd)\n",
    "    y_test_boxcox = boxcox1p(y_test, lambd)\n",
    "\n",
    "    print('Starting train')\n",
    "    with mlflow.start_run(run_name=f'exg_{exg_number}_boxcox') as run:\n",
    "        run_id = run.info.run_id\n",
    "        experiment_id = run.info.experiment_id\n",
    "        print(\"MLflow:\")\n",
    "        print(\"  run_id:\", run_id)\n",
    "        print(\"  experiment_id:\", experiment_id)\n",
    "\n",
    "        # MLflow params\n",
    "        print(\"Parameters:\")\n",
    "        print(\"  depth:\", depth)\n",
    "        print(\"  learning_rate:\", learning_rate)\n",
    "        print(\"  iterations:\", iterations)\n",
    "        mlflow.log_param(\"depth\", depth)\n",
    "        mlflow.log_param(\"learning_rate\", learning_rate)\n",
    "        mlflow.log_param(\"iterations\", iterations)\n",
    "        mlflow.log_param(\"od_type\", od_type)\n",
    "        mlflow.log_param(\"od_wait\", od_wait)\n",
    "        mlflow.log_param(\"lambd_boxcox\", lambd)\n",
    "        mlflow.log_param(\"loss_alpha\", alpha)\n",
    "\n",
    "        # Create and fit model\n",
    "        model = cb.CatBoostRegressor(\n",
    "            depth=depth, iterations=iterations, learning_rate=learning_rate, loss_function=OrgRmseObjective(alpha=alpha),\n",
    "            task_type='CPU', random_seed=13, verbose=verbose, eval_metric=OrgRmseMetric(alpha=alpha),\n",
    "            od_type=od_type, od_wait=od_wait\n",
    "        )\n",
    "\n",
    "        model.fit(X_train, y_train_boxcox,\n",
    "                        eval_set=(X_test, y_test_boxcox))\n",
    "        \n",
    "        model.save_model(f\"models/cb_regressor_exg_{exg_number}_boxcox_org_loss.cbm\")\n",
    "        \n",
    "        predictions = model.predict(X_test)\n",
    "        signature = infer_signature(X_test, predictions)\n",
    "        metrics = {\n",
    "           \"mse\": mean_absolute_error(y_test_boxcox, predictions),\n",
    "           \"rmse\": mean_squared_error(y_test_boxcox, predictions, squared=False),\n",
    "           \"mae\": mean_squared_error(y_test_boxcox, predictions),\n",
    "           \"target_metric\": custom_metric(y_test_boxcox, predictions, alpha=alpha)\n",
    "        }\n",
    "        \n",
    "        mlflow.log_metrics(metrics)\n",
    "        mlflow.catboost.log_model(model, artifact_path, signature=signature)\n",
    "        \n",
    "        # task_1 part\n",
    "        preds_df = pd.DataFrame(predictions)\n",
    "        y_df = pd.DataFrame(y_test_boxcox)\n",
    "        preds_df.to_csv(f'test_preds/y_preds_exg_{exg_number}.csv')\n",
    "        y_df.to_csv(f'test_preds/y_test_exg_{exg_number}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a531c313-5765-456a-ae97-12af942e7460",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 4\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=1000, verbose=50, learning_rate=0.01, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46e93a1-d9ef-4adb-b812-acb2b25ae1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 5\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=500, verbose=10, learning_rate=0.005, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c783060-9079-456a-8cfb-bf9ccb972883",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 6\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=1000, verbose=50, learning_rate=0.01, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37550f6a-831e-4e1b-9c78-38cd14956a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 7\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=1000, verbose=50, learning_rate=0.001, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e49563d-8d0c-4075-a32c-a1ee1b401360",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 8\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=1000, verbose=50, learning_rate=0.001, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffc04ce-4c35-4e26-ad7a-f7adfb5b3dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "exg_number = 9\n",
    "X_train_full = dd.read_parquet(PATH_TO_X_TRAIN, engine=\"pyarrow\")\n",
    "y_train_full = dd.read_parquet(PATH_TO_Y_TRAIN, engine=\"pyarrow\")\n",
    "print(f'training model for exgauster {exg_number}')\n",
    "make_model(X_train_full, y_train_full, exg_number, iterations=1000, verbose=50, learning_rate=0.001, od_wait=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20582fd-7b55-426c-9739-35e524b82ca6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e6e6cf-08f6-4cc9-8573-9b974e7256a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
